{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minecraft-python JavaScript 24\n",
      "jijkiest-scraper Jupyter Notebook 0\n",
      "shadowsocks-installer Shell 0\n",
      "macuyiko.github.io HTML 0\n",
      "blog JavaScript 1\n",
      "lfs_rcode R 0\n",
      "pdbmbook-docker Shell 0\n",
      "aoe2predict R 5\n",
      "webscrapingfordatascience Python 12\n",
      "adbmirror Python 2\n",
      "palettestealer-suspender Visual Basic 2\n",
      "sklearn-gbmi Jupyter Notebook 0\n",
      "simple-flask-feedback-table HTML 0\n",
      "Mirai-Source-Code C 0\n",
      "pach-experiments C 0\n",
      "qlearning4k Python 0\n",
      "jythonconsole Python 0\n",
      "PacH Python 0\n",
      "ptunpacker Java 1\n",
      "pdf-background-remover Java 0\n",
      "java-screenlocker Java 0\n",
      "dagobah CSS 0\n",
      "jr CSS 1\n",
      "locationaware-cpntools-extension Java 1\n",
      "weiyun-api Python 21\n",
      "bibtex-dblp-tools Java 0\n",
      "fodina-experiments Java 0\n",
      "reg-pfa-fork Java 0\n",
      "web-socket-js JavaScript 0\n",
      "sliceit-solver-genetic Java 1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "session = requests.Session()\n",
    "url = 'https://github.com/{}'\n",
    "username = 'Macuyiko'\n",
    "r = session.get(url.format(username), params={'page': 1, 'tab':\n",
    "'repositories'})\n",
    "html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "is_normal_user = False\n",
    "repos_element = html_soup.find(class_='repo-list')\n",
    "if not repos_element:\n",
    "    is_normal_user = True\n",
    "    repos_element = html_soup.find(id='user-repositories-list')\n",
    "repos = repos_element.find_all('li')\n",
    "for repo in repos:\n",
    "    name = repo.find('h3').find('a').get_text(strip=True)\n",
    "    language = repo.find(attrs={'itemprop': 'programmingLanguage'})\n",
    "    language = language.get_text(strip=True) if language else 'unknown'\n",
    "    stars = repo.find('a', attrs={'href': re.compile('\\/stargazers')})\n",
    "    stars = int(stars.get_text(strip=True).replace(',', '')) if stars else 0\n",
    "    print(name, language, stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_url(url,username):\n",
    "    r = session.get(url, params={'page': 1, 'tab':'repositories'})\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    is_normal_user = False\n",
    "    repos_element = html_soup.find(class_='repo-list')\n",
    "    if not repos_element:\n",
    "        is_normal_user = True\n",
    "        repos_element = html_soup.find(id='user-repositories-list')\n",
    "    repos = repos_element.find_all('li')\n",
    "    \n",
    "    for repo in repos:\n",
    "        name = repo.find('h3').find('a').get_text(strip=True)\n",
    "        language = repo.find(attrs={'itemprop': 'programmingLanguage'})\n",
    "        language = language.get_text(strip=True) if language else 'unknown'\n",
    "        stars = repo.find('a', attrs={'href': re.compile('\\/stargazers')})\n",
    "        stars = int(stars.get_text(strip=True).replace(',', '')) if stars else 0\n",
    "        \n",
    "        print(name, language, stars)\n",
    "    nextpage=html_soup.find('div',class_='pagination').find('a',string='Next')\n",
    "    if nextpage:\n",
    "        next=nextpage.get('href')\n",
    "        print(next)\n",
    "        call_url(next,username)\n",
    "    else:\n",
    "        print(\"Over\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "session = requests.Session()\n",
    "url = 'https://github.com/{}'\n",
    "username = 'sankalp7654'\n",
    "urls=url.format(username)\n",
    "\n",
    "call_url(urls,username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_urls(url):\n",
    "    r = session.get(url, params={'page': 1, 'tab':'repositories'})\n",
    "    html_soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    is_normal_user = False\n",
    "    repos_element = html_soup.find(class_='repo-list')\n",
    "    if not repos_element:\n",
    "        is_normal_user = True\n",
    "        repos_element = html_soup.find(id='user-repositories-list')\n",
    "    repos = repos_element.find_all('li')\n",
    "    for repo in repos:\n",
    "        name = repo.find('h3').find('a').get_text(strip=True)\n",
    "        language = repo.find(attrs={'itemprop': 'programmingLanguage'})\n",
    "        language = language.get_text(strip=True) if language else 'unknown'\n",
    "        stars = repo.find('a', attrs={'href': re.compile('\\/stargazers')})\n",
    "        stars = int(stars.get_text(strip=True).replace(',', '')) if stars else 0\n",
    "        print(name, language, stars)\n",
    "    nextpage=html_soup.find('div',class_='pagination').find_all('a')\n",
    "    if nextpage.get_text(strip=True)=='Next':\n",
    "        next=nextpage.get('href')\n",
    "        print(next)\n",
    "        call_url(next)\n",
    "    else:\n",
    "        print(\"hi\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
